# -*- coding: utf-8 -*-
"""Untitled114.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kb2k1pLW2w91bXwIvW2UMYnYuNj44nuo
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import joblib

class RFIDRNNModelTrain:

    def __init__(self, window_size=500):
        self.window_size = window_size
        self.scaler = StandardScaler()
        self.model = None

    def preprocess_data(self, data):
        tags_with_antenna_3_or_4 = data[(data['ANTENA'] == 3) | (data['ANTENA'] == 4)]['TAG'].unique()
        data = data[data['TAG'].isin(tags_with_antenna_3_or_4)]
        data = data[(data['TIPO'] == 1) & (data['ANTENA'] != 1)]
        data = self.filter_outliers(data)
        valid_samples = data[data['RESULTADO'] == 1]['ID_AMOSTRA'].unique()
        data = data[data['ID_AMOSTRA'].isin(valid_samples)]
        return data

    def filter_outliers(self, data):
        valid_data = data[data['RESULTADO'] == 1]
        invalid_data = data[data['RESULTADO'] == 0]
        rssi_valid_low = valid_data['RSSI'].quantile(0.10)
        rssi_invalid_high = invalid_data['RSSI'].quantile(0.90)

        valid_data = valid_data[valid_data['RSSI'] > rssi_valid_low]
        valid_tags = valid_data['TAG'].value_counts()
        valid_data = valid_data[valid_data['TAG'].isin(valid_tags[valid_tags >= 3].index)]
        invalid_data = invalid_data[invalid_data['RSSI'] < rssi_invalid_high]

        data_filtered = pd.concat([valid_data, invalid_data])
        return data_filtered

    def extract_features(self, data):
        data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'], unit='ms')
        data = data.set_index('TIMESTAMP')

        features = []
        labels = []

        for (id_amostra, tag), tag_data in data.groupby(['ID_AMOSTRA', 'TAG']):
            tag_windows = tag_data.resample(f'{self.window_size}ms')
            for window, window_data in tag_windows:
                if len(window_data) > 0:
                    feature = {}
                    feature['ID_AMOSTRA'] = id_amostra
                    feature['TAG'] = tag
                    feature['max_rssi'] = window_data['RSSI'].max()
                    feature['min_rssi'] = window_data['RSSI'].min()
                    feature['mean_rssi'] = window_data['RSSI'].mean()
                    feature['RSSI_norm'] = (window_data['RSSI'] - window_data['RSSI'].min()) / (window_data['RSSI'].max() - window_data['RSSI'].min())
                    antennas = [1, 2, 3, 4]
                    for antenna in antennas:
                        feature[f'antenna_{antenna}'] = window_data[window_data['ANTENA'] == antenna]['RSSI'].max() if len(window_data[window_data['ANTENA'] == antenna]) > 0 else -100

                    features.append(feature)
                    labels.append(window_data['RESULTADO'].mode()[0])

        features_df = pd.DataFrame(features)
        labels_df = pd.Series(labels)
        return features_df, labels_df

    def load_and_preprocess_data(self, file_path):
        data = pd.read_csv(file_path)
        data = self.preprocess_data(data)
        features, labels = self.extract_features(data)
        return features, labels

    def train_model(self, train_file_path, test_file_path):
        train_features, train_labels = self.load_and_preprocess_data(train_file_path)
        test_features, test_labels = self.load_and_preprocess_data(test_file_path)

        train_features_numeric = train_features.select_dtypes(include=[np.number])
        test_features_numeric = test_features.select_dtypes(include=[np.number])

        # Oversampling using SMOTE
        smote = SMOTE()
        train_features_resampled, train_labels_resampled = smote.fit_resample(train_features_numeric, train_labels)

        train_features_scaled = self.scaler.fit_transform(train_features_resampled)
        test_features_scaled = self.scaler.transform(test_features_numeric)

        joblib.dump(self.scaler, 'scaler.pkl')
        scaler_loaded = joblib.load('scaler.pkl')

        train_features_reshaped = np.array(train_features_scaled).reshape((train_features_scaled.shape[0], train_features_scaled.shape[1], 1))
        test_features_reshaped = np.array(test_features_scaled).reshape((test_features_scaled.shape[0], test_features_scaled.shape[1], 1))

        # Create LSTM model
        self.model = Sequential()
        self.model.add(LSTM(128, input_shape=(train_features_reshaped.shape[1], 1), return_sequences=False))
        self.model.add(Dropout(0.4))
        self.model.add(Dense(1, activation='sigmoid'))

        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

        # Compute class weights
        class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_resampled), y=train_labels_resampled)
        class_weights_dict = dict(enumerate(class_weights))

        self.model.fit(train_features_reshaped, train_labels_resampled, epochs=100, batch_size=64,
                       validation_data=(test_features_reshaped, test_labels),
                       callbacks=[early_stopping], class_weight=class_weights_dict)

        test_predictions = self.model.predict(test_features_reshaped)
        test_predictions = (test_predictions > 0.5).astype(int)

        precision, recall, thresholds = precision_recall_curve(test_labels, test_predictions)
        desired_recall = 0.96
        threshold = thresholds[np.argmax(recall >= desired_recall)]

        test_predictions = (test_predictions > threshold).astype(int)

        print(classification_report(test_labels, test_predictions))
        conf_matrix = confusion_matrix(test_labels, test_predictions)
        print("Confusion Matrix:\n", conf_matrix)

        plt.figure(figsize=(10, 7))
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix')
        plt.show()

if __name__ == "__main__":
    train_file_path = 'amostra_02.csv'
    test_file_path = 'amostra_03.csv'

    model = RFIDRNNModelTrain()
    model.train_model(train_file_path, test_file_path)